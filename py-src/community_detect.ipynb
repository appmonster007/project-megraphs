{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing required libraries for creating graph object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import mmread\n",
    "from Base import Graph\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "#visualization libraries, not required as such for main algorithm\n",
    "from pyvis.network import Network\n",
    "import networkx as nx\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialising and creating instances of graph object using different *.mtx files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# karate = mmread('soc-karate.mtx')\n",
    "# webedu = mmread('web-edu.mtx')\n",
    "# internet = mmread('tech-internet-as.mtx')\n",
    "\n",
    "karate = mmread('../assets/S_soc-karate.mtx')\n",
    "webedu = mmread('../assets/M_web-edu.mtx')\n",
    "internet = mmread('../assets/L_tech-internet-as.mtx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G1 = Graph(mtxfilepath='../assets/S_soc-karate.mtx')\n",
    "G2 = Graph(sparse=webedu)\n",
    "G3 = Graph(sparse=internet)\n",
    "print((\"-\"*50)+\"Graphs objects created\"+(\"-\"*50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphData = [['soc-karate.mtx', G1.graph.number_of_nodes(), G1.graph.number_of_edges(), G1.is_connected()],\n",
    "            ['web-edu.mtx', G2.graph.number_of_nodes(), G2.graph.number_of_edges(), G2.is_connected()],\n",
    "            ['tech-internet-as.mtx', G3.graph.number_of_nodes(), G3.graph.number_of_edges(), G3.is_connected()]]\n",
    "            \n",
    "display(pd.DataFrame(graphData, columns=[\"Name\", \"Size\", 'Edges', \"connected\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Centralities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EGO centrality\n",
    "# print(G.ego_centrality_node(4))\n",
    "# print(\"ego graph made\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding lfvc node\n",
    "\n",
    "lfvc1 = G1.lfvc_node(0)\n",
    "lfvc2 = G2.lfvc_node(0)\n",
    "# lfvc3 = G3.lfvc_node(0)\n",
    "print(lfvc1)\n",
    "print(lfvc2)\n",
    "# print(lfvc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding nodes of interest\n",
    "graphData = [['soc-karate.mtx', G1.nodes_of_interest()],\n",
    "            ['web-edu.mtx', G2.nodes_of_interest()],\n",
    "            ['tech-internet-as.mtx', G3.nodes_of_interest()]]\n",
    "display(pd.DataFrame(graphData, columns=[\"Name\", \"Nodes of interest: \"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding Centralities of smallest size graph, i.e. soc-karate\n",
    "\n",
    "print(\"soc-karate :\")\n",
    "dc1 = G1.degree_centrality()\n",
    "cc1 = G1.closeness_centrality()\n",
    "bc1 = G1.betweenness_centrality()\n",
    "ec1 = G1.eigenvector_centrality()\n",
    "clc1 = G1.clustering_coefficient_node(0)\n",
    "lfvc_val = G1.lfvc()\n",
    "nhc1 = G1.neighbourhood_hopset(0,2)\n",
    "\n",
    "\n",
    "data = [['lfvc', lfvc_val],\n",
    "        ['degree centrality', dc1],\n",
    "        ['closeness centrality', cc1],\n",
    "        ['betweenness centrality', bc1],\n",
    "        ['eigenvector centrality', ec1],\n",
    "        ['neighbouring hopset', nhc1],\n",
    "        ['Clusters of node 1', clc1]]\n",
    "\n",
    "display(pd.DataFrame(data, columns=[\"Centrality\", \"value\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding nodes of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_interest1 = G1.nodes_of_interest()\n",
    "nodes_interest2 = G2.nodes_of_interest()\n",
    "nodes_interest3 = G3.nodes_of_interest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Centralities at nodes of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding Centralities of medium size graph, i.e. web-edu\n",
    "\n",
    "print(\"web-edu :\")\n",
    "for i in nodes_interest2:\n",
    "    print(\"\\nNode \", i)\n",
    "    cc2 = G2.closeness_centrality_node(i)\n",
    "    clc2 = G2.clustering_coefficient_node(i)\n",
    "    ec2 = G2.ego_centrality_node(i)\n",
    "    lfvc_val2 = G2.lfvc_node(i)\n",
    "    nhc2 = G2.neighbourhood_hopset(i,2)\n",
    "    eig_c2 = G2.eigenvector_centrality_node(i)\n",
    "\n",
    "    data = [['lfvc', lfvc_val2],\n",
    "        ['closeness centrality', cc2],\n",
    "        ['Clusters of node 1', clc2],\n",
    "        ['neighbouring hopset', nhc2],\n",
    "        ['ego centrality', ec2],\n",
    "        ['eigenvector centrality', eig_c2]]\n",
    "\n",
    "    display(pd.DataFrame(data, columns=[\"Centrality\", \"value\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding Centralities of largest size graph, i.e. tech-internet-as\n",
    "\n",
    "print(\"tech-internet-as :\")\n",
    "for i in nodes_interest3:\n",
    "    print(\"\\nNode \", i)\n",
    "    cc3 = G3.closeness_centrality_node(i)\n",
    "    clc3 = G3.clustering_coefficient_node(i)\n",
    "    ec3 = G3.ego_centrality_node(i)\n",
    "    lfvc_val3 = G3.lfvc_node(i)\n",
    "    nhc3 = G3.neighbourhood_hopset(i,2)\n",
    "    eig_c3 = G3.eigenvector_centrality_node(i)\n",
    "\n",
    "    data = [['lfvc', lfvc_val3],\n",
    "        ['closeness centrality', cc3],\n",
    "        ['Clusters of node 1', clc3],\n",
    "        ['neighbouring hopset', nhc3],\n",
    "        ['ego centrality', ec3],\n",
    "        ['eigenvector centrality', eig_c3]]\n",
    "\n",
    "    display(pd.DataFrame(data, columns=[\"Centrality\", \"value\"]))\n",
    "\n",
    "\n",
    "\n",
    "# dc3 = G3.degree_centrality()\n",
    "# cc3 = G3.closeness_centrality()\n",
    "# bc3 = G3.betweenness_centrality()\n",
    "# eig_c3 = G3.eigenvector_centrality()\n",
    "# clc3 = G3.clustering_coefficient_node(0)\n",
    "# lfvc_val3 = G3.lfvc_node(0)\n",
    "# nhc3 = G3.neighbourhood_hopset(0,2)\n",
    "# print((\"-\"*100))\n",
    "# print(\"lfvc\")\n",
    "# print(lfvc_val3)\n",
    "\n",
    "# data = [[1, 'lfvc', lfvc_val3],\n",
    "#         [2, 'degree centrality', len(dc3)],\n",
    "#         [3, 'closeness centrality', len(cc3)],\n",
    "#         [4, 'betweenness centrality', len(bc3)],\n",
    "#         [5, 'eigenvector centrality', len(eig_c3)],\n",
    "#         [6, 'neighbouring hopset', nhc3],\n",
    "#         [7, 'Clusters of node 1', clc3]]\n",
    "\n",
    "# print(tabulate(data, headers=[\"#\", \"Centrality\", \"len of array/value\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep community detection using greedy lfvc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'webedu_nt'\n",
    "g_obj = G2\n",
    "dc: tuple() = g_obj.greedy_community_detection(q=50, function='node_lfvc')\n",
    "print(dc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def community_visualizer_matplot(dc,G,layout = nx.kamada_kawai_layout):\n",
    "    Gnx = G.graph\n",
    "    pos=layout(Gnx) #change layout if needed\n",
    "    # labels = nx.get_edge_attributes(Gnx,'weight')\n",
    "    colors=['green' if i in dc else 'red' for i in range(len(Gnx.nodes))]\n",
    "    # nx.draw_networkx_edge_labels(Gnx,pos,edge_labels=labels)\n",
    "    nx.draw_networkx(Gnx,pos,node_color=colors,node_size=300,width=0.3)\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "def community_visualizer_pyvis(file,dc,G_obj):\n",
    "    G = G_obj.graph\n",
    "    nt = Network(height='100%', width='100%', bgcolor='#94b8b8', font_color='black')\n",
    "    # nt = Network(height='750px', width='100%')\n",
    "\n",
    "    colors = []\n",
    "    for i in G.nodes:\n",
    "        if(i in dc[0]):\n",
    "            colors.append('blue')\n",
    "        elif(i in dc[1]):\n",
    "            colors.append('green')\n",
    "        else:\n",
    "            colors.append('red')\n",
    "            \n",
    "    nt.add_nodes([i for i in G.nodes],color = colors)\n",
    "    for n1,n2 in G.edges:\n",
    "        nt.add_edge(int(n1),int(n2))\n",
    "    # print(nt)\n",
    "    nt.barnes_hut(gravity=-80000, central_gravity=0.3, spring_length=250, spring_strength=0.001, damping=0.09, overlap=0)\n",
    "\n",
    "    nt.toggle_physics(False)\n",
    "    nt.inherit_edge_colors(False)\n",
    "    nt.show_buttons(filter_=['physics']) #make =True for all buttons\n",
    "    nt.show(file)\n",
    "\n",
    "\n",
    "# community_visualizer_matplot(dc,G1,nx.spring_layout)\n",
    "community_visualizer_pyvis('../assets/'+filename+'.html', dc, g_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Community reduction\n",
    "Reducing Commnunity and representing it using single node in graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_community_graph(dc, g_obj):\n",
    "    n_g: nx.Graph = deepcopy(g_obj.graph)\n",
    "    om : set = dc[0]\n",
    "    nu : set = dc[1].difference(om)\n",
    "    nnode = n_g.number_of_nodes()+len(nu)\n",
    "    n_g.add_node(nnode)\n",
    "    for y in om:\n",
    "        for x in nu:\n",
    "            if(n_g.has_edge(y,x)):\n",
    "                n_g.add_edge(y,nnode, weight=1)\n",
    "                break\n",
    "\n",
    "    n_g.remove_nodes_from(nu)\n",
    "    n_nu = om.union([nnode])\n",
    "    return ((om, n_nu), Graph(nx_graph=n_g))\n",
    "\n",
    "rc, ng_obj = reduce_community_graph(dc, g_obj)\n",
    "community_visualizer_pyvis('../assets/'+filename+'_rc.html', rc, ng_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing centralities of representative node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnode = list(rc[1].difference(rc[0]))[0]\n",
    "print(\"\\nNode \", nnode)\n",
    "cc2 = ng_obj.closeness_centrality_node(nnode)\n",
    "clc2 = ng_obj.clustering_coefficient_node(nnode)\n",
    "ec2 = ng_obj.ego_centrality_node(nnode)\n",
    "lfvc_val2 = ng_obj.lfvc_node(nnode)\n",
    "nhc2 = ng_obj.neighbourhood_hopset(nnode,2)\n",
    "eig_c2 = ng_obj.eigenvector_centrality_node(nnode)\n",
    "\n",
    "data = [['lfvc', lfvc_val2],\n",
    "    ['closeness centrality', cc2],\n",
    "    ['Clusters of node 1', clc2],\n",
    "    ['neighbouring hopset', nhc2],\n",
    "    ['ego centrality', ec2],\n",
    "    ['eigenvector centrality', eig_c2]]\n",
    "\n",
    "display(pd.DataFrame(data, columns=[\"Centrality\", \"value\"]))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
