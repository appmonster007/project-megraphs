{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Base import Graph\n",
    "import pandas as pd\n",
    "import csv\n",
    "import time\n",
    "import sys\n",
    "#visualization libraries, not required as such for main algorithm\n",
    "import networkx as nx\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(sys.argv) == 1:\n",
    "    filename = 'L_tech-internet-as.mtx'\n",
    "else:\n",
    "    filename = sys.argv[1]\n",
    "G1 = Graph(mtxfilepath=f'../assets/{filename}')\n",
    "\n",
    "# dc1 = G1.degree_centrality()\n",
    "# ec1 = G1.eigenvector_centrality()\n",
    "# egc1 = G1.ego_centrality()\n",
    "# clc1 = G1.clustering_coefficient()\n",
    "# nhc1 = G1.neighbourhood_hopset_graph(2)\n",
    "\n",
    "\n",
    "# lfvc_val = G1.lfvc()\n",
    "csv_file = open(f'{filename}_csv', 'w')\n",
    "writer = csv.writer(csv_file)\n",
    "len = G1.graph.number_of_nodes()\n",
    "print(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = open('reddit_data.csv', 'w')\n",
    "writer = csv.writer(csv_file)\n",
    "writer.writerow(['Nodes','Normal Betweenness','Custom Betweenness','Degree', 'Closeness'])\n",
    "reddit_file_director = '../assets/reddit_threads'\n",
    "directory = os.fsencode(reddit_file_director)\n",
    "    \n",
    "for file in os.listdir(directory):\n",
    "    print(directory.decode('UTF-8') + '/' + file.decode('UTF-8'))\n",
    "    G1 = Graph(mtxfilepath=directory.decode('UTF-8') + '/' + file.decode('UTF-8'))\n",
    "    start = time.thread_time_ns()\n",
    "    bc1 = nx.betweenness_centrality(G1.graph)\n",
    "    print(f\"\\t\\tNumber of edges:{G1.graph.number_of_edges()} and nodes:{G1.graph.number_of_nodes()}\")\n",
    "    normal_b = (time.thread_time_ns() - start)\n",
    "    print(f\"\\t\\tTime normal algorithm: {normal_b:.4F} nano seconds\")\n",
    "    start = time.thread_time_ns()\n",
    "    rbc1 = G1.betweenness_centrality()\n",
    "    random_b = (time.thread_time_ns() - start)\n",
    "    print(f\"\\t\\tTime custom algorithm: {random_b:.4F} nano seconds\")\n",
    "    start = time.thread_time_ns()\n",
    "    dbc1 = G1.degree_centrality()\n",
    "    degree = (time.thread_time_ns() - start)\n",
    "    print(f\"\\t\\tTime degree algorithm: {degree:.4F} nano seconds\")\n",
    "    start = time.thread_time_ns()\n",
    "    cc1 = G1.closeness_centrality()\n",
    "    closess = (time.thread_time_ns() - start)\n",
    "    print(f\"\\t\\tTime closeness algorithm: {closess:.4F} nano seconds\")\n",
    "    writer.writerow([G1.graph.number_of_nodes(),normal_b,random_b,degree, closess])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = open('proteins_data.csv', 'w')\n",
    "writer = csv.writer(csv_file)\n",
    "writer.writerow(['Nodes','Normal Betweenness','Custom Betweenness','Degree', 'Closeness'])\n",
    "\n",
    "reddit_file_director = '../assets/proteins'\n",
    "directory = os.fsencode(reddit_file_director)\n",
    "    \n",
    "for file in os.listdir(directory):\n",
    "    print(directory.decode('UTF-8') + '/' + file.decode('UTF-8'))\n",
    "    G1 = Graph(mtxfilepath=directory.decode('UTF-8') + '/' + file.decode('UTF-8'))\n",
    "    start = time.thread_time_ns()\n",
    "    bc1 = nx.betweenness_centrality(G1.graph)\n",
    "    print(f\"\\t\\tNumber of edges:{G1.graph.number_of_edges()} and nodes:{G1.graph.number_of_nodes()}\")\n",
    "    normal_b = (time.thread_time_ns() - start)\n",
    "    print(f\"\\t\\tTime normal algorithm: {normal_b:.4F} nano seconds\")\n",
    "    start = time.thread_time_ns()\n",
    "    rbc1 = G1.betweenness_centrality()\n",
    "    random_b = (time.thread_time_ns() - start)\n",
    "    print(f\"\\t\\tTime custom algorithm: {random_b:.4F} nano seconds\")\n",
    "    start = time.thread_time_ns()\n",
    "    dbc1 = G1.degree_centrality()\n",
    "    degree = (time.thread_time_ns() - start)\n",
    "    print(f\"\\t\\tTime degree algorithm: {degree:.4F} nano seconds\")\n",
    "    start = time.thread_time_ns()\n",
    "    cc1 = G1.closeness_centrality()\n",
    "    closess = (time.thread_time_ns() - start)\n",
    "    print(f\"\\t\\tTime closeness algorithm: {closess:.4F} nano seconds\")\n",
    "    writer.writerow([G1.graph.number_of_nodes(),normal_b,random_b,degree, closess])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
