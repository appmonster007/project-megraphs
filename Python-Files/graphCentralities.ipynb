{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing required libraries for creating graph object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import mmread\n",
    "from tabulate import tabulate\n",
    "from Base import Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialising and creating instances of graph object using different *.mtx files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# karate = mmread('soc-karate.mtx')\n",
    "# webedu = mmread('web-edu.mtx')\n",
    "# internet = mmread('tech-internet-as.mtx')\n",
    "\n",
    "karate = mmread('../assets/S_soc-karate.mtx')\n",
    "webedu = mmread('../assets/M_web-edu.mtx')\n",
    "internet = mmread('../assets/L_tech-internet-as.mtx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G1 = Graph(mtxfilepath='../assets/S_soc-karate.mtx')\n",
    "G2 = Graph(sparse=webedu)\n",
    "G3 = Graph(sparse=internet)\n",
    "print((\"-\"*50)+\"Graphs made\"+(\"-\"*50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(G1.graph.size())\n",
    "print(G2.graph.size())\n",
    "print(G3.graph.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if instantiated graphs are connected\n",
    "\n",
    "c1 = G1.is_connected()\n",
    "c2 = G2.is_connected()\n",
    "c3 = G3.is_connected()\n",
    "print(f'G1 is connected: {c1}')\n",
    "print(f'G2 is connected: {c2}')\n",
    "print(f'G3 is connected: {c3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Centralities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EGO centrality\n",
    "# print(G.ego_centrality_node(4))\n",
    "# print(\"ego graph made\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding lfvc node\n",
    "\n",
    "lfvc1 = G1.lfvc_node(0)\n",
    "lfvc2 = G2.lfvc_node(0)\n",
    "# lfvc3 = G3.lfvc_node(0)\n",
    "print(lfvc1)\n",
    "print(lfvc2)\n",
    "# print(lfvc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding nodes of interest\n",
    "print(\"Nodes of interest: \")\n",
    "print(f'small:\\t{G1.nodes_of_interest()}')\n",
    "print(f'medium:\\t{G2.nodes_of_interest()}')\n",
    "print(f'large:\\t{G3.nodes_of_interest()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding Centralities of smallest size graph, i.e. soc-karate\n",
    "\n",
    "print(\"soc-karate :\")\n",
    "dc1 = G1.degree_centrality()\n",
    "cc1 = G1.closeness_centrality()\n",
    "bc1 = G1.betweenness_centrality()\n",
    "ec1 = G1.eigenvector_centrality()\n",
    "clc1 = G1.clustering_coefficient_node(0)\n",
    "lfvc_val = G1.lfvc()\n",
    "nhc1 = G1.neighbourhood_hopset(0,2)\n",
    "\n",
    "\n",
    "data = [[1, 'lfvc', len(lfvc_val)],\n",
    "        [2, 'degree centrality', len(dc1)],\n",
    "        [3, 'closeness centrality', len(cc1)],\n",
    "        [4, 'betweenness centrality', len(bc1)],\n",
    "        [5, 'eigenvector centrality', len(ec1)],\n",
    "        [6, 'neighbouring hopset', nhc1],\n",
    "        [7, 'Clusters of node 1', clc1]]\n",
    "\n",
    "print(tabulate(data, headers=[\"#\", \"Centrality\", \"len of array/value\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding nodes of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_interest1 = G1.nodes_of_interest()\n",
    "nodes_interest2 = G2.nodes_of_interest()\n",
    "nodes_interest3 = G3.nodes_of_interest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding Centralities of medium size graph, i.e. web-edu\n",
    "\n",
    "print(\"web-edu :\")\n",
    "for i in nodes_interest2:\n",
    "    print(\"\\nNode \", i)\n",
    "    cc2 = G2.closeness_centrality_node(i)\n",
    "    clc2 = G2.clustering_coefficient_node(i)\n",
    "    ec2 = G2.ego_centrality_node(i)\n",
    "    lfvc_val2 = G2.lfvc_node(i)\n",
    "    nhc2 = G2.neighbourhood_hopset(i,2)\n",
    "    eig_c2 = G2.eigenvector_centrality_node(i)\n",
    "\n",
    "    data = [[1, 'lfvc', lfvc_val2],\n",
    "        [2, 'closeness centrality', cc2],\n",
    "        [3, 'Clusters of node 1', clc2],\n",
    "        [4, 'neighbouring hopset', nhc2],\n",
    "        [5, 'ego centrality', ec2],\n",
    "        [6, 'eigenvector centrality', eig_c2]]\n",
    "\n",
    "    print (tabulate(data, headers=[\"#\", \"Centrality\", \"Value\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding Centralities of largest size graph, i.e. tech-internet-as\n",
    "\n",
    "print(\"tech-internet-as :\")\n",
    "for i in nodes_interest3:\n",
    "    print(\"\\nNode \", i)\n",
    "    cc3 = G3.closeness_centrality_node(i)\n",
    "    clc3 = G3.clustering_coefficient_node(i)\n",
    "    ec3 = G3.ego_centrality_node(i)\n",
    "    lfvc_val3 = G3.lfvc_node(i)\n",
    "    nhc3 = G3.neighbourhood_hopset(i,2)\n",
    "    eig_c3 = G3.eigenvector_centrality_node(i)\n",
    "\n",
    "    data = [[1, 'lfvc', lfvc_val3],\n",
    "        [2, 'closeness centrality', cc3],\n",
    "        [3, 'Clusters of node 1', clc3],\n",
    "        [4, 'neighbouring hopset', nhc3],\n",
    "        [5, 'ego centrality', ec3],\n",
    "        [6, 'eigenvector centrality', eig_c3]]\n",
    "\n",
    "    print (tabulate(data, headers=[\"#\", \"Centrality\", \"Value\"]))\n",
    "\n",
    "\n",
    "# dc3 = G3.degree_centrality()\n",
    "# cc3 = G3.closeness_centrality()\n",
    "# bc3 = G3.betweenness_centrality()\n",
    "# eig_c3 = G3.eigenvector_centrality()\n",
    "# clc3 = G3.clustering_coefficient_node(0)\n",
    "# lfvc_val3 = G3.lfvc_node(0)\n",
    "# nhc3 = G3.neighbourhood_hopset(0,2)\n",
    "# print((\"-\"*100))\n",
    "# print(\"lfvc\")\n",
    "# print(lfvc_val3)\n",
    "\n",
    "# data = [[1, 'lfvc', lfvc_val3],\n",
    "#         [2, 'degree centrality', len(dc3)],\n",
    "#         [3, 'closeness centrality', len(cc3)],\n",
    "#         [4, 'betweenness centrality', len(bc3)],\n",
    "#         [5, 'eigenvector centrality', len(eig_c3)],\n",
    "#         [6, 'neighbouring hopset', nhc3],\n",
    "#         [7, 'Clusters of node 1', clc3]]\n",
    "\n",
    "# print(tabulate(data, headers=[\"#\", \"Centrality\", \"len of array/value\"]))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
