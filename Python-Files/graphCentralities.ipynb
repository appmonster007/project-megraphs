{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import stat\n",
    "from networkx.algorithms.components.connected import is_connected\n",
    "from networkx.classes.function import neighbors\n",
    "from networkx.linalg.algebraicconnectivity import fiedler_vector\n",
    "import scipy as sp\n",
    "import networkx as nx\n",
    "from scipy.io import mmread\n",
    "from scipy.sparse.coo import coo_matrix\n",
    "from scipy.sparse.linalg import eigs\n",
    "from numpy import linalg as LA\n",
    "import numpy as np\n",
    "import csv\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Graph object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graph:\n",
    "    \"\"\"\n",
    "    Encapsulating a graph as a single object\n",
    "    Graph Class encapsulates a networkx graph and exposes medthods for finding centtralities and related metrics\n",
    "    Currently implemented metrics include:\n",
    "    - Degree Centrality\n",
    "    - Closeness Centrality\n",
    "    - Betweenness Centrality\n",
    "    - Eigenvector Centrality\n",
    "    - LFVC\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, sparse):\n",
    "        self.graph = nx.from_scipy_sparse_matrix(sparse)\n",
    "        self.adj = nx.adjacency_matrix(self.graph)\n",
    "        self.laplacian = nx.laplacian_matrix(self.graph)\n",
    "\n",
    "    \n",
    "    def degree_centrality(self):\n",
    "        return nx.degree_centrality(self.graph)\n",
    "\n",
    "\n",
    "    def closeness_centrality(self):\n",
    "        return nx.closeness_centrality(self.graph)\n",
    "\n",
    "\n",
    "    def closeness_centrality_node(self, node):\n",
    "        return nx.closeness_centrality(self.graph, node)\n",
    "\n",
    "\n",
    "    def betweenness_centrality(self):\n",
    "        return nx.betweenness_centrality(self.graph, k = min(self.graph.number_of_nodes() , 500))\n",
    "\n",
    "\n",
    "    def eigenvector_centrality(self):\n",
    "        return nx.eigenvector_centrality(self.graph)\n",
    "\n",
    "\n",
    "    def eigenvector_centrality_node(self, node):\n",
    "        eigenvector , eigen_val = self.eigenvector_atindex(-1)\n",
    "        nodes = list(self.graph.nodes(data = True))\n",
    "        n = nodes[node]\n",
    "        inv = 1/eigen_val\n",
    "        centrality = 0\n",
    "        for i in self.graph.neighbors(n[0]):\n",
    "            data = self.graph.get_edge_data(i, n[0], 0)\n",
    "            centrality += data[\"weight\"] * eigenvector[i]\n",
    "        return centrality * inv\n",
    "\n",
    "\n",
    "    def is_connected(self):\n",
    "        return nx.is_connected(self.graph)\n",
    "\n",
    "\n",
    "    def lfvc(self):\n",
    "        if (not self.is_connected()):\n",
    "            return \"Not possible\"\n",
    "        fiedler_vector = nx.fiedler_vector(self.graph)\n",
    "        lfvclist = []\n",
    "        for i in self.graph.nodes(data = True):\n",
    "            lfvcthis = 0\n",
    "            for j in self.graph.neighbors(i[0]):\n",
    "                lfvcthis += (fiedler_vector[j]-fiedler_vector[i[0]])*(fiedler_vector[j]-fiedler_vector[i[0]])\n",
    "            lfvclist.append(lfvcthis)\n",
    "        return lfvclist\n",
    "\n",
    "\n",
    "    def lfvc_node(self, node):\n",
    "        if (not self.is_connected()):\n",
    "            return \"Not possible\"\n",
    "        lfvcthis = 0\n",
    "        nodes = list(self.graph.nodes(data = True))\n",
    "        n = nodes[node]\n",
    "        fiedler_vector = self.eigenvector_atindex(1)[0]\n",
    "        fiedler = fiedler_vector[n[0]]\n",
    "        for j in self.graph.neighbors(n[0]):\n",
    "            lfvcthis += (fiedler_vector[j]-fiedler)*(fiedler_vector[j]-fiedler)\n",
    "        return lfvcthis\n",
    "        \n",
    "\n",
    "    def neighbourhood_hopset(self, index, k = 10):\n",
    "        nbrs = set([index])\n",
    "        for l in range(k):\n",
    "            nbrs = set((nbr for n in nbrs for nbr in self.graph[n]))\n",
    "        return len(nbrs)\n",
    "\n",
    "\n",
    "    def clustering_coefficient(self):\n",
    "        return nx.clustering(self.graph)\n",
    "\n",
    "\n",
    "    def clustering_coefficient_node(self, node):\n",
    "        return nx.clustering(self.graph, node)\n",
    "\n",
    "\n",
    "    def ego_centrality_node(self, node):\n",
    "        g = nx.ego_graph(self.graph, node)\n",
    "        nodes = list(g.nodes(data = True))\n",
    "        n = node\n",
    "        for i in nodes:\n",
    "            if i[0] == node:\n",
    "                n = i\n",
    "                break\n",
    "        centrality =  nx.betweenness_centrality(g)\n",
    "        return centrality[node]\n",
    "\n",
    "\n",
    "    def nodes_of_interest(self):\n",
    "        l = list(nx.degree_centrality(self.graph))\n",
    "        mean = statistics.mean(l)\n",
    "        median = statistics.median_high(l)\n",
    "        closest_mean = min(l, key = lambda x:abs(x-mean))\n",
    "        max_value = max(l)\n",
    "        min_value = min(l)\n",
    "        return l.index(median), l.index(closest_mean), l.index(min_value), l.index(max_value)\n",
    "\n",
    "\n",
    "    def eigenvector_atindex(self, a):\n",
    "        eig_values, eig_vectors = eigs(self.adj)\n",
    "        evr = np.sort(eig_values.real)\n",
    "        vector_pos = np.where(eig_values.real == evr[a])[0][0]\n",
    "        vector = np.transpose(eig_vectors)[vector_pos]\n",
    "        eig_val = evr[a]\n",
    "        return vector.real, eig_val\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialising and creating instances of graph object using different *.mtx files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# karate = mmread('../assets/S_soc-karate.mtx')\n",
    "# webedu = mmread('../assets/M_web-edu.mtx')\n",
    "# internet = mmread('../assets/L_tech-internet-as.mtx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "karate = mmread('soc-karate.mtx')\n",
    "webedu = mmread('web-edu.mtx')\n",
    "internet = mmread('tech-internet-as.mtx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G1 = Graph(karate)\n",
    "G2 = Graph(webedu)\n",
    "G3 = Graph(internet)\n",
    "print((\"-\"*50)+\"Graphs made\"+(\"-\"*50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G1.graph.size()\n",
    "G2.graph.size()\n",
    "G3.graph.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if instantiated graphs are connected\n",
    "\n",
    "c1 = G1.is_connected()\n",
    "c2 = G2.is_connected()\n",
    "c3 = G3.is_connected()\n",
    "print(f'G1 is connected: {c1}')\n",
    "print(f'G2 is connected: {c2}')\n",
    "print(f'G3 is connected: {c3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Centralities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EGO centrality\n",
    "# print(G.ego_centrality_node(4))\n",
    "# print(\"ego graph made\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding lfvc node\n",
    "\n",
    "lfvc1 = G1.lfvc_node(0)\n",
    "lfvc2 = G2.lfvc_node(0)\n",
    "# lfvc3 = G3.lfvc_node(0)\n",
    "print(lfvc1)\n",
    "print(lfvc2)\n",
    "# print(lfvc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding nodes of interest\n",
    "print(\"Nodes of interest: \")\n",
    "print(G1.nodes_of_interest())\n",
    "print(G2.nodes_of_interest())\n",
    "print(G3.nodes_of_interest())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding Centralities of smallest size graph, i.e. soc-karate\n",
    "\n",
    "print(\"soc-karate :\")\n",
    "dc1 = G1.degree_centrality()\n",
    "cc1 = G1.closeness_centrality()\n",
    "bc1 = G1.betweenness_centrality()\n",
    "ec1 = G1.eigenvector_centrality()\n",
    "clc1 = G1.clustering_coefficient_node(0)\n",
    "lfvc_val1 = G1.lfvc()\n",
    "nhc1 = G1.neighbourhood_hopset(0,2)\n",
    "print((\"-\"*100))\n",
    "print(\"lfvc\")\n",
    "print(lfvc_val1)\n",
    "print((\"-\"*100))\n",
    "print(\"degree centrality\")\n",
    "print(dc1)\n",
    "print((\"-\"*100))\n",
    "print(\"closeness centrality\")\n",
    "print(cc1)\n",
    "print((\"-\"*100))\n",
    "print(\"betweenness centrality\")\n",
    "print(bc1)\n",
    "print((\"-\"*100))\n",
    "print(\"eigenvector centrality\")\n",
    "print(ec1)\n",
    "print((\"-\"*100))\n",
    "print(\"Clusters of node 1\")\n",
    "print(clc1)\n",
    "print((\"-\"*100))\n",
    "print(\"neighbouring hopset\")\n",
    "print(nhc1)\n",
    "print((\"-\"*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding Centralities of medium size graph, i.e. web-edu\n",
    "\n",
    "print(\"web-edu :\")\n",
    "nodes_interest1 = G1.nodes_of_interest()\n",
    "nodes_interest2 = G2.nodes_of_interest()\n",
    "nodes_interest3 = G3.nodes_of_interest()\n",
    "for i in nodes_interest3:\n",
    "    print(\"node \", i)\n",
    "    cc2 = G3.closeness_centrality_node(i)\n",
    "    clc2 = G3.clustering_coefficient_node(i)\n",
    "    ec2 = G3.ego_centrality_node(i)\n",
    "    lfvc_val2 = G3.lfvc_node(i)\n",
    "    nhc2 = G3.neighbourhood_hopset(i,2)\n",
    "    eig_c2 = G3.eigenvector_centrality_node(i)\n",
    "    print((\"-\"*100))\n",
    "    print(\"lfvc\")\n",
    "    print(lfvc_val2)\n",
    "    print((\"-\"*100))\n",
    "    print((\"-\"*100))\n",
    "    print(\"closeness centrality\")\n",
    "    print(cc2)\n",
    "    print((\"-\"*100))\n",
    "    print((\"-\"*100))\n",
    "    print(\"Clusters of node 1\")\n",
    "    print(clc2)\n",
    "    print((\"-\"*100))\n",
    "    print(\"neighbouring hopset\")\n",
    "    print(nhc2)\n",
    "    print((\"-\"*100))\n",
    "    print(\"ego centrality\")\n",
    "    print(ec2)\n",
    "    print((\"-\"*100))\n",
    "    print(\"eigenvector centrality\")\n",
    "    print(eig_c2)\n",
    "    print((\"-\"*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding Centralities of largest size graph, i.e. tech-internet-as\n",
    "\n",
    "print(\"tech-internet-as :\")\n",
    "# dc3 = G3.degree_centrality()\n",
    "# cc3 = G3.closeness_centrality()\n",
    "# bc3 = G3.betweenness_centrality()\n",
    "# ec3 = G3.eigenvector_centrality()\n",
    "# clc3 = G3.clustering_coefficient_node(0)\n",
    "lfvc_val3 = G3.lfvc_node(0)\n",
    "nhc3 = G3.neighbourhood_hopset(0,2)\n",
    "print((\"-\"*100))\n",
    "print(\"lfvc\")\n",
    "print(lfvc_val3)\n",
    "# print((\"-\"*100))\n",
    "# print(\"degree centrality\")\n",
    "# print(dc3)\n",
    "# print((\"-\"*100))\n",
    "# print(\"closeness centrality\")\n",
    "# print(cc3)\n",
    "# print((\"-\"*100))\n",
    "# print(\"betweenness centrality\")\n",
    "# print(bc3)\n",
    "# print((\"-\"*100))\n",
    "# print(\"eigenvector centrality\")\n",
    "# print(ec3)\n",
    "# print((\"-\"*100))\n",
    "# print(\"Clusters of node 1\")\n",
    "# print(clc3)\n",
    "# print((\"-\"*100))\n",
    "# print(\"neighbouring hopset\")\n",
    "# print(nhc3)\n",
    "# print((\"-\"*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
